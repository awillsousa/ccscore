{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "communist-dallas",
   "metadata": {},
   "source": [
    "### Anotação das cadeias de correferências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib\n",
    "\n",
    "PATH_REDACOES = \"../ccscore/data/Corpus_Redacoes_Dissertacao.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega a base de redações\n",
    "df_redacoes = pickle.load(open(PATH_REDACOES, 'rb'))\n",
    "df_redacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_redacoes['Nota'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-science",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_redacoes['Competência 4'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-theology",
   "metadata": {},
   "source": [
    "Por meio dos valores de correlação obtidos, percebe-se que existe uma forte relação positiva\n",
    "entre a Nota Final e o valor da Competência 4.\n",
    "Já os valores de relação entre a Competência 4 e as demais, mostra que existe uma relação positiva\n",
    "moderada entre as Competências, o que faz com que exista uma influência equivalente entre a Competência 4\n",
    "e todas as outras competências. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-destination",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_redacoes[['Nota', \n",
    "                               'Competência 1',\n",
    "                               'Competência 2',\n",
    "                               'Competência 3',\n",
    "                               'Competência 4',\n",
    "                               'Competência 5']])\n",
    "correlation = df.corr(method='pearson')\n",
    "correlation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-passion",
   "metadata": {},
   "source": [
    "Pelo teste t de Student feito a seguir, podemos ver que pelo do p-valor ser 0 (zero),\n",
    "a relação entre a Competência 4 e a Nota Final é estatisticamente significante. Enquanto, \n",
    "o relacionamento entre a Competência 4 e as demais, pode ser considerado estatisticamente \n",
    "significante, mas que o mesmo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "nota = df_redacoes[['Nota']].to_numpy()\n",
    "\n",
    "compt_1 = df_redacoes[['Competência 1']].to_numpy()\n",
    "compt_2 = df_redacoes[['Competência 2']].to_numpy()\n",
    "compt_3 = df_redacoes[['Competência 3']].to_numpy()\n",
    "compt_4 = df_redacoes[['Competência 4']].to_numpy()\n",
    "compt_5 = df_redacoes[['Competência 5']].to_numpy()\n",
    "\n",
    "res = ttest_ind(nota, compt_1)\n",
    "print(\"Nota, Competência 1: \",res)\n",
    "\n",
    "res = ttest_ind(nota, compt_2)\n",
    "print(\"Nota, Competência 2: \",res)\n",
    "\n",
    "res = ttest_ind(nota, compt_3)\n",
    "print(\"Nota, Competência 3: \",res)\n",
    "\n",
    "res = ttest_ind(nota, compt_4)\n",
    "print(\"Nota, Competência 4: \",res)\n",
    "\n",
    "res = ttest_ind(nota, compt_5)\n",
    "print(\"Nota, Competência 5: \",res)\n",
    "\n",
    "res = ttest_ind(compt_1, compt_4)\n",
    "print(\"Competência 1, Competência 4: \",res)\n",
    "\n",
    "res = ttest_ind(compt_2, compt_4)\n",
    "print(\"Competência 2, Competência 4: \",res)\n",
    "\n",
    "res = ttest_ind(compt_3, compt_4)\n",
    "print(\"Competência 3, Competência 4: \",res)\n",
    "\n",
    "res = ttest_ind(compt_5, compt_4)\n",
    "print(\"Competência 5, Competência 4: \",res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-stake",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = df_redacoes[['Nota', 'Competência 4']]\n",
    "min_max_scaler = MinMaxScaler()\n",
    "df[['Nota', 'Competência 4']] = min_max_scaler.fit_transform(df[['Nota', 'Competência 4']])\n",
    "\n",
    "df.sort_values(by=['Competência 4'], inplace=True)\n",
    "\n",
    "lines = df.reset_index().plot.line(y='Competência 4', x='index', c='Darkblue')\n",
    "\n",
    "#df['Nota'].value_counts().hist()\n",
    "#df['Competência 4'].value_counts().hist()\n",
    "#lines = df.reset_index().plot.scatter(x='Competência 4', y='Nota', c='Darkblue')\n",
    "#df_contagem = df['Nota'].value_counts()\n",
    "#df_contagem = pd.concat([df_contagem, df['Competência 4'].value_counts()], axis=0)\n",
    "#df_contagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contagem de palavras das redacoes\n",
    "total_palavras = 0\n",
    "\n",
    "for i,redacao in df_redacao.iterrows():\n",
    "    texto = redacao['Texto']\n",
    "    texto = texto.replace(\"\\n\", ' ')\n",
    "\n",
    "    doc = nlp(texto)\n",
    "    total_palavras += len([token.text for token in doc if token.is_punct != True])\n",
    "\n",
    "total_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total de palavras de todas as redações: {total_palavras}\")\n",
    "print(f\"Média de palavras por redação: {round(total_palavras/total_redacoes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "#redacao_exemplo = nlp(df_redacao[[\"Texto\"]][0])\n",
    "i_redacao = 10\n",
    "print(df_redacao[\"Texto\"][i_redacao])\n",
    "df_redacao.iloc[i_redacao]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grava os arquivos as redações em arquivos para anotação\n",
    "# utilizando o software CORP\n",
    "\n",
    "for i,redacao in df_redacao.iterrows():\n",
    "    texto = redacao['Texto']\n",
    "    arq_redacao = f'../CORP/Entrada/redacao_{i}.txt'\n",
    "    try:\n",
    "        with open(arq_redacao, 'w') as f:\n",
    "            f.write(texto)\n",
    "    except IOError as e:\n",
    "        print(f\"Erro ao processar o arquivo {arq_redacao}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga das redacoes \n",
    "\n",
    "import re\n",
    "\n",
    "# Corrige os textos dos arquivos, alterando\n",
    "# principalmente, situações de pontuação \n",
    "# sem espaço subsequente\n",
    "def ajusta_texto(texto):\n",
    "    \n",
    "    pats = [r\"\\..[A-Za-z^\\s]\",   # ponto \".\" sem espaço subsequente\n",
    "            r\",.[A-Za-z^\\s]\",    # virgula \",\" sem espaço subsequente\n",
    "            r\"\\(.[A-Za-z^\\s]\",    # parentese \"(\" sem espaço antecedente\n",
    "            r\".[A-Za-z^\\s]\\)\"    # parentese \"(\" sem espaço subsequente\n",
    "           ]\n",
    "    chars = [\".\", \",\", \"(\", \")\"]\n",
    "     \n",
    "    for c, pat in zip(chars, pats):\n",
    "        matches = re.findall(pat, texto, re.MULTILINE)         \n",
    "\n",
    "        for m in matches:\n",
    "            pos_m = texto.find(m)\n",
    "            pos_dot = m.find(c)\n",
    "            \n",
    "            if c == \"(\":\n",
    "                if not(texto[pos_m-1] == \" \"):\n",
    "                    m_rep =  f\" {m}\"\n",
    "                    texto = texto.replace(m, m_rep)\n",
    "            else:\n",
    "                pos_m = pos_m + pos_dot\n",
    "                if ((pos_m+1) < len(texto)):\n",
    "                    if not(texto[pos_m+1] == \" \"):\n",
    "                        if c == ',' and texto[pos_m+1] in \"0123456789\":\n",
    "                            continue\n",
    "                        m_rep = f\"{m[:pos_dot+1]} {m[pos_dot+1:]}\"\n",
    "                        texto = texto.replace(m, m_rep)\n",
    "    \n",
    "    texto = texto.replace(\"\\'\\'\", \"\\\"\")\n",
    "    texto = texto.replace(\" .\", \".\")\n",
    "    texto = texto.replace(\" ,\", \",\")\n",
    "    \n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texto_redacao)\n",
    "print(100*\"=\")\n",
    "print(ajusta_texto(texto_redacao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-bearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"1,23 milhões ver sem amigos , pois faz. parte(ou mais parte),ou não faria e,outra vez(quem sabe) . \"\n",
    "ajusta_texto(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando um arquivo contendo todas as redações\n",
    "PATH_ALL = \"./redacoes/\"\n",
    "l_separador = \"\\n\"\n",
    "\n",
    "for arq_essay in arqs_essays:\n",
    "    texto = \"\"\n",
    "    texto += f\"<ARQUIVO: \\\"{arq_essay}\\\">\"\n",
    "    texto += l_separador    \n",
    "    with open(arq_essay, \"r\") as f_essay:\n",
    "        texto += ajusta_texto(\"\".join(f_essay.readlines()))\n",
    "    \n",
    "    texto += l_separador        \n",
    "    with open(f\"{PATH_ALL}all_texts.txt\", \"a\") as f_todos:\n",
    "        f_todos.write(texto)\n",
    "       \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-store",
   "metadata": {},
   "source": [
    "### Avaliando os erros ortograficos presentes nos arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-consultation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import language_tool_python as ltp\n",
    "\n",
    "tool = ltp.LanguageTool('pt-BR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_redacao = arqs_essays[25]\n",
    "\n",
    "texto_redacao = \"\"\n",
    "with open(path_redacao) as f:\n",
    "    texto_redacao = \"\".join(f.readlines())\n",
    "\n",
    "texto_redacao \n",
    "erros = tool.check(ajusta_texto(texto_redacao))\n",
    "\n",
    "print(texto_redacao)\n",
    "print()\n",
    "print(str(erros).replace('), Match', \"), \\n\\nMatch)\"))\n",
    "#print(\"\\n\\n\".join([str(x) for x in erros]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
