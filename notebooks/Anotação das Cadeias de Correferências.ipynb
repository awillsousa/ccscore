{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "communist-dallas",
   "metadata": {},
   "source": [
    "### Anotação das cadeias de correferências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "PATH_REDACOES = \"../ccscore/data/Corpus_Redacoes_Dissertacao.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega a base de redações\n",
    "df_redacao = pickle.load(open(PATH_REDACOES, 'rb'))\n",
    "df_redacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conta da quantidade de arquivos de redações\n",
    "total_redacoes = df_redacao.shape[0]\n",
    "print(f\"Total de redações: {total_redacoes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-stake",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('pt_core_news_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contagem de palavras das redacoes\n",
    "total_palavras = 0\n",
    "\n",
    "for i,redacao in df_redacao.iterrows():\n",
    "    texto = redacao['Texto']\n",
    "    texto = texto.replace(\"\\n\", ' ')\n",
    "\n",
    "    doc = nlp(texto)\n",
    "    total_palavras += len([token.text for token in doc if token.is_punct != True])\n",
    "\n",
    "total_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total de palavras de todas as redações: {total_palavras}\")\n",
    "print(f\"Média de palavras por redação: {round(total_palavras/total_redacoes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "#redacao_exemplo = nlp(df_redacao[[\"Texto\"]][0])\n",
    "i_redacao = 1691\n",
    "print(df_redacao[\"Texto\"][i_redacao])\n",
    "df_redacao.iloc[i_redacao]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grava os arquivos as redações em arquivos para anotação\n",
    "# utilizando o software CORP\n",
    "if False:\n",
    "    for i,redacao in df_redacao.iterrows():\n",
    "        texto = redacao['Texto']\n",
    "        arq_redacao = f'../CORP/Entrada/redacao_{i}.txt'\n",
    "        try:\n",
    "            with open(arq_redacao, 'w') as f:\n",
    "                f.write(texto)\n",
    "        except IOError as e:\n",
    "            print(f\"Erro ao processar o arquivo {arq_redacao}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([[10,20,30],[11,22,33],[1,2,3]], \n",
    "                  columns=['col1', 'col2', 'col3'])\n",
    "\n",
    "df['x'] = ''\n",
    "\n",
    "#df['x'][0] = 'a'\n",
    "df.at[0,'x'] = 'a'\n",
    "df.at[1,'x'] = 'b'\n",
    "df.at[2,'x'] = 'c'\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga das anotações das cadeias de coreferência\n",
    "import glob\n",
    "import xmltodict\n",
    "\n",
    "PATH_CORREF='../CORP/Saida/XML'\n",
    "\n",
    "cadeias_corref = {}\n",
    "erros = []\n",
    "for name in glob.glob(f'{PATH_CORREF}/*.xml'):    \n",
    "    id_redacao = name.split('redacao_')[1]\n",
    "    id_redacao = int(id_redacao.split('.')[0])\n",
    "    #print(name)\n",
    "    #print(id_redacao)\n",
    "    texto_xml = \"\"\n",
    "    try:\n",
    "        with open(name, 'r', encoding='utf-8') as f:\n",
    "            texto_xml = \" \".join(f.readlines())\n",
    "    except IOError:\n",
    "        print(\"Erro na abertura do arquivo\")\n",
    "        \n",
    "    try:\n",
    "        cadeias_corref[id_redacao] = xmltodict.parse(texto_xml)    \n",
    "    except Exception as e:\n",
    "        erros.append((id_redacao, name))\n",
    "        print(\"Erro:\", str(e))\n",
    "        \n",
    "    \n",
    "#corp_red['ConteudoXML']['Cadeias']['Cadeia_21']\n",
    "#corp_red['ConteudoXML'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "erros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_CORP = \"../ccscore/data/Corpus_Redacoes_CORP.pickle\"\n",
    "\n",
    "with open(PATH_CORP, 'wb') as f:    \n",
    "    pickle.dump(cadeias_corref, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sentenca = 3\n",
    "cadeias_corref[0]['ConteudoXML']['Sentencas'][f\"sentenca_{num_sentenca}\"]['@conteudo']\n",
    "cadeias_corref[0]['ConteudoXML']['Cadeias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentenca(num_redacao, num_sentenca):\n",
    "    return cadeias_corref[num_redacao]['ConteudoXML']['Sentencas'][f\"sentenca_{num_sentenca}\"]['@conteudo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-bearing",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_redacao = 0\n",
    "cadeias = cadeias_corref[num_redacao]['ConteudoXML']['Cadeias'].items()\n",
    "for cadeia, sns in cadeias:\n",
    "    print(f\"\\n{cadeia}\")\n",
    "    for elem_cadeia in sns.items():\n",
    "        for elem in elem_cadeia[1]:\n",
    "            #print(elem)\n",
    "            sn_elem = elem['@sintagma']\n",
    "            categoria = elem['@Categoria']\n",
    "            print(f\"\\t{categoria} - {sn_elem}\")\n",
    "            s = get_sentenca(num_redacao, elem['@sentenca'])\n",
    "            s = s.replace(sn_elem, f\"<<{sn_elem}>>\")\n",
    "            print(f\"\\t{s}\")\n",
    "            \n",
    "            \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
